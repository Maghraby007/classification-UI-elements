{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7deb6a2-b11d-4383-8c01-09b024927820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0febdcde-9912-47ce-a8d1-ad2156e6da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "directory=\"your dataset file path\"\n",
    "categories=['button','checkbox','dropdown','image','table'] # I chose these five elemenet from the whole data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d8a588-949f-4b74-ab5b-cf70467fbd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images\n",
    "img_size=120\n",
    "data= []\n",
    "for category in categories:\n",
    "    folder=os.path.join(directory,category)\n",
    "    label= categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path=os.path.join(folder, img)\n",
    "        img_arr= cv2.imread(img_path)\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr= cv2.resize(img_arr,(img_size,img_size))\n",
    "        data.append([img_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa7b816-f1af-45a0-b030-6c9feddb855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract the features and labels from the training and testing sets\n",
    "train_images, train_labels = zip(*train_data)\n",
    "test_images, test_labels = zip(*test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c1383f-d966-4424-993c-77ca9b381ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(train_images)\n",
    "y=np.array(train_labels)\n",
    "x=x/255 #normalizing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a412624-3263-4a77-bf3c-f1383fa88609",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d375a99-68b9-442a-87ee-cd76fecea482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten , Dense, Dropout, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d0f1a7-2d88-4634-9dd2-18e31e7e7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718c7294-1dfd-4d3d-9621-aaf76162f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 118, 118, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 59, 59, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 57, 57, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6422656   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,460,998\n",
      "Trainable params: 6,460,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model.build(input_shape=(None, 120, 120, 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd68552-55fd-4302-bc78-378efe37d18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "114/114 [==============================] - 82s 696ms/step - loss: 1.0251 - accuracy: 0.6143 - val_loss: 0.6420 - val_accuracy: 0.7778\n",
      "Epoch 2/8\n",
      "114/114 [==============================] - 78s 686ms/step - loss: 0.5418 - accuracy: 0.8077 - val_loss: 0.5024 - val_accuracy: 0.8296\n",
      "Epoch 3/8\n",
      "114/114 [==============================] - 78s 686ms/step - loss: 0.3676 - accuracy: 0.8743 - val_loss: 0.4632 - val_accuracy: 0.8420\n",
      "Epoch 4/8\n",
      "114/114 [==============================] - 78s 682ms/step - loss: 0.2705 - accuracy: 0.9045 - val_loss: 0.3978 - val_accuracy: 0.8741\n",
      "Epoch 5/8\n",
      "114/114 [==============================] - 77s 680ms/step - loss: 0.1782 - accuracy: 0.9405 - val_loss: 0.4485 - val_accuracy: 0.8370\n",
      "Epoch 6/8\n",
      "114/114 [==============================] - 77s 680ms/step - loss: 0.1390 - accuracy: 0.9545 - val_loss: 0.4441 - val_accuracy: 0.8519\n",
      "Epoch 7/8\n",
      "114/114 [==============================] - 77s 678ms/step - loss: 0.1090 - accuracy: 0.9668 - val_loss: 0.4615 - val_accuracy: 0.8741\n",
      "Epoch 8/8\n",
      "114/114 [==============================] - 77s 678ms/step - loss: 0.0771 - accuracy: 0.9759 - val_loss: 0.5009 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddd531ed60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=8,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae2a93c-0fa4-4522-b6ff-49c92ac6f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test folder path\n",
    "test_directory=\"file_path\"\n",
    "test_categories=['button','checkbox','dropdown','image','table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c616f758-5e2e-4a7f-9a06-6ce4f5131ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= []\n",
    "size=120\n",
    "for category in test_categories:\n",
    "    folder=os.path.join(test_directory,category)\n",
    "    label= test_categories.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        test_img_path=os.path.join(folder, img)\n",
    "        test_img_arr= cv2.imread(test_img_path)\n",
    "        test_img_arr = cv2.cvtColor(test_img_arr, cv2.COLOR_BGR2GRAY)\n",
    "        test_img_arr= cv2.resize(test_img_arr,(size,size))\n",
    "        test_data.append([test_img_arr, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92ac0b2-68d6-45dd-a264-21f3d018c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(test_images)\n",
    "Y_test=np.array(test_labels)\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3d2af-a08c-44d5-85f9-94f8e945097b",
   "metadata": {},
   "source": [
    "## Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a6473b-bf69-4f13-8ecb-9bb4d59ede5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4435 - accuracy: 0.9052\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc31b976-cef5-4cb7-834b-de7bd9433e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 44.35294568538666\n",
      "Test Accuracy: 90.52320122718811\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:\", loss*100)\n",
    "print(\"Test Accuracy:\", accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4f196-a082-43f4-ba4b-461504420c24",
   "metadata": {},
   "source": [
    "## predicting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c669f895-78aa-46f5-bfac-cf1d350f6695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image path\n",
    "pred_image_path = \"prediction_image.png\" \n",
    "\n",
    "# Read the image\n",
    "pred_image = cv2.imread(pred_image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "pred_image = cv2.cvtColor(pred_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Resize the image to the desired size\n",
    "pred_image = cv2.resize(pred_image, (img_size, img_size))\n",
    "\n",
    "# Reshape the image for prediction\n",
    "pred_image= np.reshape(pred_image, (1, 120, 120, 1))\n",
    "\n",
    "# Normalize the image pixel values (if necessary)\n",
    "#pred_image = pred_image / 255.0  # Normalize pixel values between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0afe5f3-59dc-426d-9937-444e5d1f3e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "Predicted label: table\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a trained model stored in the 'model' variable\n",
    "predictions = model.predict(pred_image)\n",
    "\n",
    "# Get the predicted label/index\n",
    "predicted_label_index = np.argmax(predictions)\n",
    "\n",
    "# Assuming you have a list of category labels\n",
    "predicted_label = categories[predicted_label_index]\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a477bbc-b914-4bc5-9721-b345638adf9e",
   "metadata": {},
   "source": [
    "## saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6528d95b-5cad-44d5-86a2-62e53d4ba51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('savemodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fc3199-9e20-45b1-b5b7-345a0d383787",
   "metadata": {},
   "source": [
    "## Creating Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eb6ae1f-5317-4f43-8104-765cdcc0149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d144e352-e9e2-4736-96e6-01e15b78c7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 187ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      button       0.94      0.84      0.89       247\n",
      "    checkbox       0.86      0.93      0.89       210\n",
      "    dropdown       0.89      0.89      0.89       174\n",
      "       image       0.94      0.95      0.95       213\n",
      "       table       0.89      0.93      0.91       169\n",
      "\n",
      "    accuracy                           0.91      1013\n",
      "   macro avg       0.90      0.91      0.91      1013\n",
      "weighted avg       0.91      0.91      0.91      1013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(Y_test, y_pred_labels, target_names=categories)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06302a06-938e-43f5-badd-285d29f30603",
   "metadata": {},
   "source": [
    "## predect an image with more than one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bef6453b-e39e-4794-8df5-8af8cfd758b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Shapes: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the image\n",
    "image_path = 'elements.jpg'\n",
    "img = cv2.imread(image_path, 0)  # Load as grayscale\n",
    "\n",
    "# Apply Gaussian blur to reduce noise and improve edge detection\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Find contours in the edged image\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "threshold=5000 #change threshold if you wanted\n",
    "\n",
    "filtered_contours = [contour for contour in contours if cv2.contourArea(contour) > threshold]\n",
    "\n",
    "# Count the total number of shapes\n",
    "num_shapes = len(filtered_contours)\n",
    "\n",
    "print(f'Total Number of Shapes: {num_shapes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c5df72d-add6-4dfd-94b9-7f2b999a7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes around each detected contour and crop them\n",
    "for i, contour in enumerate(filtered_contours):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "   \n",
    "        # Crop the box and save as a separate image\n",
    "        cropped_box = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(f'result_{i}.jpg', cropped_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21cbd491-70e0-4caf-bcf0-a710bc4eec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicted label: ['table', 'checkbox', 'table', 'dropdown']\n",
      "Predicted label probability: [100.0, 100.0, 100.0, 99.9998688697815]\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the cropped images are saved\n",
    "box_directory = 'direcrtory path where images will be saved'\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "box_files = [f for f in os.listdir(box_directory) if f.startswith('result_')]\n",
    "\n",
    "# Sort the files based on the box number (i)\n",
    "box_files.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "# Initialize an empty list to store the cropped boxes\n",
    "cropped_boxes = []\n",
    "predicted_label=[]\n",
    "percentage_list=[]\n",
    "# Get the class labels\n",
    "class_labels = ['button','checkbox','dropdown','image','table'] #hia hia el categories \n",
    "# Load and append each cropped box to the list\n",
    "for box_file in box_files:\n",
    "    box_path = os.path.join(box_directory, box_file)\n",
    "    cropped_box = cv2.imread(box_path)\n",
    "    # Convert the image to grayscale\n",
    "    cropped_box = cv2.cvtColor(cropped_box, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the image\n",
    "    cropped_box = cv2.resize(cropped_box, (img_size, img_size))\n",
    "    # Reshape the image for prediction\n",
    "    cropped_box= np.reshape(cropped_box, (1, 120, 120, 1))\n",
    "\n",
    "    cropped_boxes.append(cropped_box)\n",
    "    # Assuming you have a trained model stored in the 'model' variable\n",
    "    predictions = model.predict(cropped_box)\n",
    "\n",
    "    # Get the predicted label/index\n",
    "    predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "    predicted_label.append(categories[predicted_label_index])\n",
    "\n",
    "# Print the predicted label\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1d8fb-4608-4df9-b1fd-9a38e3ee9ed9",
   "metadata": {},
   "source": [
    "## delete the saved image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "103309dc-be83-4b18-a5fc-48355cd6372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#box_files = [f for f in os.listdir(box_directory) if f.startswith('box_')]\n",
    "#for box_file in box_files:\n",
    " #   box_path = os.path.join(box_directory, box_file)\n",
    "  #  os.remove(box_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d956a-10df-470f-9a5c-370c2f124d26",
   "metadata": {},
   "source": [
    "## create html code according to the predicted elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2039db2-26ed-43a2-ad81-26eb05dbcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_elements(element_types):\n",
    "    html_code = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
    "    <title>Dynamic Elements</title>\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN\" crossorigin=\"anonymous\">\n",
    "</head>\n",
    "<body>\n",
    "\"\"\"\n",
    "\n",
    "    for element_type in element_types:\n",
    "        if element_type == 'button':\n",
    "            html_code += \"\"\"<a class=\"btn btn-primary\" href=\"#\" role=\"button\">Link</a>\n",
    "                        <input class=\"btn btn-primary\" type=\"button\" value=\"Input\">\"\"\"\n",
    "        elif element_type == 'checkbox':\n",
    "            html_code += '<input type=\"checkbox\"> Checkbox<br>'\n",
    "        elif element_type == 'table':\n",
    "            html_code += \"\"\"\n",
    "<table class=\"table table-dark table-striped\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>ID</th>\n",
    "            <th>Name</th>\n",
    "            <th>Age</th>\n",
    "            <th>Email</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>1</td>\n",
    "            <td>John Doe</td>\n",
    "            <td>30</td>\n",
    "            <td>john@example.com</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>2</td>\n",
    "            <td>Jane Doe</td>\n",
    "            <td>28</td>\n",
    "            <td>jane@example.com</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>3</td>\n",
    "            <td>Jim Smith</td>\n",
    "            <td>35</td>\n",
    "            <td>jim@example.com</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "        elif element_type == 'image':\n",
    "            html_code += '<img src=\"\" class=\"rounded mx-auto d-block\" alt=\"Image\">'\n",
    "        elif element_type == 'dropdown':\n",
    "            html_code += \"\"\"\n",
    "<div class=\"dropdown\">\n",
    "  <a class=\"btn btn-secondary dropdown-toggle\" href=\"#\" role=\"button\" data-bs-toggle=\"dropdown\" aria-expanded=\"false\">\n",
    "    Dropdown link\n",
    "  </a>\n",
    "\n",
    "  <ul class=\"dropdown-menu\">\n",
    "    <li><a class=\"dropdown-item\" href=\"#\">Action</a></li>\n",
    "    <li><a class=\"dropdown-item\" href=\"#\">Another action</a></li>\n",
    "    <li><a class=\"dropdown-item\" href=\"#\">Something else here</a></li>\n",
    "  </ul>\n",
    "</div>\n",
    "\"\"\"\n",
    "        else:\n",
    "            return 'Invalid input. Please choose from \"button\", \"checkbox\", \"table\", \"image\", or \"dropdown\".'\n",
    "    # Add closing tags for body and html sections\n",
    "    html_code += \"\"\"\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js\" integrity=\"sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL\" crossorigin=\"anonymous\"></script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "    return html_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d55bd8-f7be-444a-bc35-0597ef4c9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input for the types of elements\n",
    "element_types = predicted_label\n",
    "\n",
    "# Generate HTML code\n",
    "html_code = generate_html_elements(element_types)\n",
    "\n",
    "# Save the HTML code to a file\n",
    "if not html_code.startswith('Invalid'):\n",
    "    with open('generated_elements.html', 'w') as file:\n",
    "        file.write(html_code)\n",
    "\n",
    "print(f\"Generated HTML code:\\n{html_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
